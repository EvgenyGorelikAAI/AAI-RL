{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highway Environment\n",
    "\n",
    "Let's look at the highway environment https://github.com/Farama-Foundation/HighwayEnv\n",
    "\n",
    "Set up the environment by adding the submodule to this folder.\n",
    "\n",
    "Setup the environment by calling \n",
    "\n",
    "```\n",
    "cd HighwayEnv\n",
    "conda activate q-learning\n",
    "python setup develop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aai/anaconda3/envs/q-learning/lib/python3.8/site-packages/gymnasium/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment GymV26Environment-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the gymnasium environment, and see what we can do in it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define observations according to the definition in https://highway-env.readthedocs.io/en/latest/observations/index.html\n",
    "\n",
    "We have the observation parameters \n",
    "- `presence` (Whether vehicle is visible in view)\n",
    "- `x`\n",
    "- `y`\n",
    "- `vx`\n",
    "- `vy`\n",
    "- `cos_h`\n",
    "- `sin_h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': {'type': 'DiscreteMetaAction'},\n",
      " 'centering_position': [0.3, 0.5],\n",
      " 'collision_reward': -1,\n",
      " 'controlled_vehicles': 1,\n",
      " 'duration': 20,\n",
      " 'ego_spacing': 2,\n",
      " 'high_speed_reward': 0.4,\n",
      " 'initial_lane_id': None,\n",
      " 'lane_change_reward': 0,\n",
      " 'lanes_count': 4,\n",
      " 'manual_control': False,\n",
      " 'normalize_reward': True,\n",
      " 'observation': {'absolute': False,\n",
      "                 'features': ['presence', 'x', 'y', 'vx', 'vy'],\n",
      "                 'features_range': {'vx': [-20, 20],\n",
      "                                    'vy': [-20, 20],\n",
      "                                    'x': [-100, 100],\n",
      "                                    'y': [-100, 100]},\n",
      "                 'normalize': False,\n",
      "                 'order': 'sorted',\n",
      "                 'type': 'Kinematics',\n",
      "                 'vehicles_count': 15},\n",
      " 'offroad_terminal': False,\n",
      " 'offscreen_rendering': False,\n",
      " 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
      " 'policy_frequency': 1,\n",
      " 'real_time_rendering': False,\n",
      " 'render_agent': True,\n",
      " 'reward_speed_range': [20, 30],\n",
      " 'right_lane_reward': 0.1,\n",
      " 'scaling': 5.5,\n",
      " 'screen_height': 150,\n",
      " 'screen_width': 600,\n",
      " 'show_trajectories': False,\n",
      " 'simulation_frequency': 15,\n",
      " 'vehicles_count': 20,\n",
      " 'vehicles_density': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aai/anaconda3/envs/q-learning/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "\n",
    "config = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 15,\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
    "        \"features_range\": {\n",
    "            \"x\": [-100, 100],\n",
    "            \"y\": [-100, 100],\n",
    "            \"vx\": [-20, 20],\n",
    "            \"vy\": [-20, 20]\n",
    "        },\n",
    "        \"absolute\": False,\n",
    "        \"order\": \"sorted\",\n",
    "        \"normalize\": False\n",
    "    },\n",
    "    \"duration\": 20,\n",
    "    \"vehicles_count\": 20,\n",
    "    \"collision_reward\": -1,\n",
    "    \"high_speed_reward\": 0.4\n",
    "}\n",
    "\n",
    "env.configure(config)\n",
    "\n",
    "pprint(env.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.       , 177.39053  ,   4.       ,  25.       ,   0.       ],\n",
       "       [  1.       ,  20.5727   ,   0.       ,  -3.343128 ,   0.       ],\n",
       "       [  1.       ,  40.825012 ,   0.       ,  -3.3453565,   0.       ],\n",
       "       [  1.       ,  62.15614  ,   0.       ,  -3.365775 ,   0.       ],\n",
       "       [  1.       ,  81.18384  ,  -4.       ,  -3.7396436,   0.       ],\n",
       "       [  1.       , 103.0921   ,  -4.       ,  -2.3286119,   0.       ],\n",
       "       [  1.       , 123.91152  ,  -4.       ,  -3.0356705,   0.       ],\n",
       "       [  1.       , 142.46057  ,   8.       ,  -3.0500135,   0.       ],\n",
       "       [  1.       , 164.62222  ,   0.       ,  -2.1595054,   0.       ],\n",
       "       [  1.       , 185.62967  ,   8.       ,  -2.391198 ,   0.       ],\n",
       "       [  0.       ,   0.       ,   0.       ,   0.       ,   0.       ],\n",
       "       [  0.       ,   0.       ,   0.       ,   0.       ,   0.       ],\n",
       "       [  0.       ,   0.       ,   0.       ,   0.       ,   0.       ],\n",
       "       [  0.       ,   0.       ,   0.       ,   0.       ,   0.       ],\n",
       "       [  0.       ,   0.       ,   0.       ,   0.       ,   0.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see, which actions we can perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LANE_LEFT', 'IDLE', 'LANE_RIGHT', 'FASTER', 'SLOWER']\n"
     ]
    }
   ],
   "source": [
    "print(list(env.action_type.actions_indexes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(obs):\n",
    "    distances_to_vehicles = np.linalg.norm(obs[:,1:2],axis=1)\n",
    "    if distances_to_vehicles[obs[:,0] > 0].min() < 0.15:\n",
    "        action = env.action_type.actions_indexes[\"SLOWER\"]\n",
    "        print(f\"SLOWER:\\t{distances_to_vehicles[obs[:,0] > 0].min()}\")\n",
    "    else:\n",
    "        action = env.action_type.actions_indexes[\"FASTER\"]\n",
    "        print(f\"FASTER:\\t{distances_to_vehicles[obs[:,0] > 0].min()}\")\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTER: 0.22860531508922577\n",
      "FASTER: 0.16660159826278687\n",
      "SLOWER: 0.06791802495718002\n",
      "SLOWER: 0.015495242550969124\n",
      "SLOWER: 0.05618380382657051\n",
      "SLOWER: 0.07327571511268616\n",
      "SLOWER: 0.08571264147758484\n",
      "SLOWER: 0.09643597900867462\n",
      "FASTER: 0.2049071490764618\n",
      "FASTER: 0.20152637362480164\n",
      "FASTER: 0.15337350964546204\n",
      "SLOWER: 0.08153873682022095\n",
      "SLOWER: 0.030872169882059097\n",
      "SLOWER: 0.025245536118745804\n",
      "SLOWER: 0.04354032874107361\n",
      "SLOWER: 0.06577606499195099\n",
      "SLOWER: 0.08851192146539688\n",
      "SLOWER: 0.11114273965358734\n",
      "SLOWER: 0.13355320692062378\n",
      "SLOWER: 0.14697128534317017\n",
      "FASTER: 0.15184777975082397\n",
      "SLOWER: 0.13167503476142883\n",
      "SLOWER: 0.11607901751995087\n",
      "SLOWER: 0.1176508441567421\n",
      "SLOWER: 0.12221099436283112\n",
      "SLOWER: 0.1273345947265625\n",
      "SLOWER: 0.13260595500469208\n",
      "SLOWER: 0.13795307278633118\n",
      "SLOWER: 0.14336296916007996\n",
      "SLOWER: 0.1488330215215683\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "print(\"Action\\tDistance to closest vehicle\")\n",
    "for _ in range(30):\n",
    "    obs, reward, done, truncated, info = env.step(get_action(obs))\n",
    "    env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cf68cbc5620f2f37a274bb61f6d37757583ee635f521547df98da585de52630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
